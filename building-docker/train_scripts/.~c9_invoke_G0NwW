#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import json
import pickle
import sys
import traceback

import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.metrics import max_error, mean_absolute_error, mean_squared_error, median_absolute_error, r2_score
from sklearn.tree import DecisionTreeRegressor

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

# The function to execute the training.
def train():
    print('Starting the training.')
    try:
        # Read in any hyperparameters that the user passed with the training job
        with open(param_path, 'r') as tc:
            trainingParams = json.load(tc)

        # Take the set of files and read them all into a single pandas dataframe
        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        if len(input_files) == 0:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, channel_name))
        raw_data = [ pd.read_csv(file, header=None) for file in input_files ]
        train_data = pd.concat(raw_data)

        # labels are in the first column
        train_y = train_data.ix[:,0]
        train_X = train_data.ix[:,1:]

        #split data into train and vaildation data
        X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=0.1, random_state=42)


        # Note that hyperparameters are always passed in as
        # strings, so we need to do any necessary conversions.
        
        criterion = trainingParams.get('criterion', None)
        if criterion is not None:
            criterion = str(criterion)
        else:
            criterion = 'gini'
        
        
        splitter = trainingParams.get('splitter', None)
        if splitter is not None:
            splitter = str(splitter)
        else:
            splitter = 'best'
        
        
        max_depth = trainingParams.get('max_depth', None)
        if max_depth is not None:
            max_depth = int(max_depth)

        min_samples_split = trainingParams.get('min_samples_split', None)
        if min_samples_split is not None:
            min_samples_split = int(min_samples_split)
        else:
            min_samples_split = 2
        
        
        min_samples_leaf = trainingParams.get('min_samples_leaf', None)
        if min_samples_leaf is not None:
            min_samples_leaf = int(min_samples_leaf)
        else:
            min_samples_leaf = 1
            
            
        min_weight_fraction_leaf = trainingParams.get('min_weight_fraction_leaf', None)
        if min_weight_fraction_leaf  is not None:
            min_weight_fraction_leaf  = int(min_weight_fraction_leaf)
        else:
            min_weight_fraction_leaf  = 0
        
        
        max_features = trainingParams.get('max_features', None)
        if max_features  is not None:
            max_features  = int(max_features)
   
   
        max_leaf_nodes = trainingParams.get('max_leaf_nodes', None)
        if max_leaf_nodes  is not None:
            max_leaf_nodes  = int(max_leaf_nodes)
      

        min_impurity_decrease = trainingParams.get('min_impurity_decrease', None)
        if min_impurity_decrease  is not None:
            min_impurity_decrease  = float(min_impurity_decrease)
        else:
            min_impurity_decrease  = 0.0


        min_impurity_split = trainingParams.get('min_impurity_split', None)
        if min_impurity_split  is not None:
            min_impurity_split  = float(min_impurity_split)
        else:
            min_impurity_split  = 1e-7
            


        # Now use scikit-learn's decision tree classifier to train the model.
        model = DecisionTreeRegressor(splitter=splitter,
                                    criterion=criterion,
                                    max_depth=max_depth,
                                    min_samples_split=min_samples_split,
                                    min_samples_leaf=min_samples_leaf,
                                    min_weight_fraction_leaf=min_weight_fraction_leaf,
                                    max_features=max_features,
                                    max_leaf_nodes=max_leaf_nodes,
                                    min_impurity_decrease=min_impurity_decrease)
                                    
        model = model.fit(train_X, train_y)

        print('Training complete.')
        
 
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)


    try:
        #testing model
        print('Testing Model.')
        y_pred = model.predict(X_valid)
        
        #model results
        print('Model Results')
        print('Max Error: ' + str(max_error(y_valid, y_pred)))
        print('Mean Absoulte Error (MAE): ' + str(mean_absolute_error(y_valid, y_pred)))
        print('Mean Squared Error (MSE): ' + str(mean_squared_error(y_valid, y_pred)))
        print('Root Mean Squared Error (RMSE): ' + str(mean_squared_error(y_valid, y_pred)**(1/2)))
        print('Median Absoulte Error: ' + str(median_absolute_error(y_valid, y_pred)))
        print('R-Squared: ' + str(r2_score(y_valid, y_pred)))


        #other model attrubutes


    
    except:
        print('TestingError: Model could not be tested.')     


        
    try:    
       # save the model
        with open(os.path.join(model_path, 'decision-tree-regression-model.pkl'), 'w') as out:
            pickle.dump(model, out)
    
    except:
        print('SaveError: Model could not be saved.')
        
        
if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
