#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import json
import pickle
import sys
import traceback

import pandas as pd
import scipy
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, fbeta_score
from sklearn.svm import SVC

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
training_path = os.path.join(input_path, 'training')
target_path = os.path.join(input_path, 'target')

# The function to execute the training.
def train():
    print('Import all information.')
    try:
        # Read in any hyperparameters that the user passed with the training job
        with open(param_path, 'r') as tc:
            trainingParams = json.load(tc)


            
        # Take the set of files and read them all into a single pandas dataframe
        train_input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        target_input_files = [ os.path.join(target_path, file) for file in os.listdir(target_path) ]
        if len(train_input_files) == 0 or len(target_input_files) == 0:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, 'training'))
                              
        data_type = trainingParams.get('data_type', None)
        if data_type is not None:
            data_type = str(data_type)
        else:
            data_type = 'numeric'
        
        print(train_input_files)
        print(target_input_files)
        
        #determine the type of data imported.  
        if data_type == 'text' or data_type == 'word':
            train_X = scipy.sparse.load_npz(train_input_files[0])
            train_y = pd.read_csv(target_input_files[0], header=None)
            print('Text data was imported.')
        else:
            train_data = pd.read_csv('train.csv', header=None)
            
            # labels are in the first column
            train_y = train_data.ix[:,0]
            train_X = train_data.ix[:,1:]
            print('numeric data was imported.')


        #split data into train and vaildation data
        X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=0.1, random_state=42)



    except Exception as e:
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during data import: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during data import: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)  
        
    try:
        print('Start training.')
        # Note that hyperparameters are always passed in as
        # strings, so we need to do any necessary conversions.
        C = trainingParams.get('C', None)
        if C is not None:
            C = float(C)
        else:
            C = 1.0

        kernel = trainingParams.get('kernel', None)
        if kernel is not None:
            kernel = str(kernel)
        else:
            kernel = 'rbf'


        shrinking = trainingParams.get('shrinking', None)
        if shrinking is not None:
            shrinking = bool(shrinking)
        else:
            shrinking = True      


        probability = trainingParams.get('probability', None)
        if probability is not None:
            probability = bool(probability)
        else:
            probability = False
            
            
        tol = trainingParams.get('tol', None)
        if tol is not None:
            tol = float(tol)
        else:
            tol = 1e-3
            
            
        max_iter = trainingParams.get('max_iter', None)
        if max_iter is not None:
            max_iter = int(max_iter)
        else:
            max_iter = -1          
            
            
        decision_function_shape = trainingParams.get('decision_function_shape', None)
        if decision_function_shape is not None:
            decision_function_shape = str(decision_function_shape)
        else:
            decision_function_shape = 'ovr'
            
            
        if kernel == 'ploy' or kernel == 'rbf' or kernel == 'sigmoid':
            
            gamma = trainingParams.get('gamma', None)
            if gamma is not None:
                gamma = float(gamma)
            else:
                gamma = 'auto'
                
            if kernel == 'ploy':
                degree = trainingParams.get('degree', None)
                if degree is not None:
                    degree = int(degree)
                else:
                    degree = 3
                    
                model = SVC(C=C, 
                            kernel=kernel,
                            gamma=gamma,
                            degree=degree,
                            max_iter=max_iter,
                            shrinking=shrinking,
                            probability=probability,
                            tol=tol,
                            decision_function_shape=decision_function_shape,
                            n_jobs=-1)
    

                
            model = SVC(C=C, 
                        kernel=kernel,
                        gamma=gamma,
                        max_iter=max_iter,
                        shrinking=shrinking,
                        probability=probability,
                        tol=tol,
                        decision_function_shape=decision_function_shape,
                        n_jobs=-1)
        else:
            model = SVC(C=C, 
                        kernel=kernel,
                        max_iter=max_iter,
                        shrinking=shrinking,
                        probability=probability,
                        tol=tol,
                        decision_function_shape=decision_function_shape)    

                                    
        model = model.fit(X_train, y_train)

        print('Training complete.')
        

    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)
        
    try:
        #testing model
        print('Testing Model.')
        y_pred = model.predict(X_valid)
        
        #model results
        print('Model Results')
        print(confusion_matrix(y_valid, y_pred))
        print('Accuracy: ' + str(accuracy_score(y_valid, y_pred)))
        print('Recall: ' + str(recall_score(y_valid, y_pred, average='weighted')))
        print('Precision: ' + str(precision_score(y_valid, y_pred, average='weighted')))
        print('F1-Score: ' + str(f1_score(y_valid, y_pred, average='weighted')))



        #other model attrubutes
        print('Parameters: ' + str(model.get_params()))
        if data_type == 'numeric' or data_type == 'numbers':
            print('Coefficients:\n' + str(pd.Series(model.coef_, index = X_train.columns).sort_values(ascending=False)))
    
    
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during testing: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during testing: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)   

    try:
        # save the model
        with open(os.path.join(model_path, 'support-vector-classification-model.pkl'), 'w') as out:
            pickle.dump(model, out)
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during model export: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during model export: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255) 

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
